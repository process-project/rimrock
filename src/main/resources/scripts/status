#!/bin/bash

QSTAT=''
SQUEUE=''
ZJH=/opt/cyfronet/bin/zeus-jobs-history
SACCT=/net/slurm/releases/production/bin/sacct
ECHO=/bin/echo
set -o pipefail

function usage {
	echo "Usage: $0 job_id [job_id...]"
}

function report_error {
	echo -e "{\n\t\"result\": \"ERROR\",\n\t\"error_message\": \"$1\"\n}"
}

function detect_rm {
	SQUEUE=$(which squeue 2>/dev/null)
	if [ $? -eq 0 ]
	then
		RM="slurm"
		return
	fi

	QSTAT=$(which qstat 2>/dev/null)
	if [ $? -eq 0 ]
	then
		RM="torque"
	fi
}

function status_torque {
	declare -A state
	state["Q"]="QUEUED"
	state["R"]="RUNNING"
	state["E"]="ERROR"
	state["C"]="COMPLETED"

	declare -a job_list=($@)

	text_output=""
	text_output_history=""

	jobs_states=$($QSTAT ${job_list[@]} 2>/dev/null | tail -n +3 | gawk '{ print $1"-"$5 }')

	for job_state in ${jobs_states}
	do
		job_id=$($ECHO ${job_state} | cut -d "." -f 1)
		raw_state=$($ECHO ${job_state} | cut -d "-" -f 2)
		text_output="${text_output}\t\t{\n\t\t\t\"job_id\": \"${job_id}\",\n\t\t\t\"job_state\": \"${state[${raw_state}]}\"\n\t\t},\n"
	done


	#check for past job data in zeus-jobs-history, jobs here should not collide with jobs gathered from qstat
	#for now the monitoring user is excluded to make the monitoring tests work

	if [ "plgmonitoring" != $USER ]
	then
		for job_id in "${job_list[@]}"
		do
			zjho=$($ZJH -f $job_id | tail -n 19)
			job_nodes=$(echo "$zjho" | grep "Nodes:" | tr -s " " | cut -d " " -f 2 2>&1)
			job_cores=$(echo "$zjho" | grep "Cores:" | tr -s " " | cut -d " " -f 2 2>&1)
			job_walltime=$(echo "$zjho" | grep "Walltime:" | tr -s " " | cut -d " " -f 2 2>&1)
			job_queuetime=$(echo "$zjho" | grep "Waited for start:" | tr -s " " | cut -d " " -f 4 2>&1)
			job_starttime=$(echo "$zjho" | grep "Start:" | tr -s " " | cut -d " " -f 2,3 2>&1)
			job_endtime=$(echo "$zjho" | grep "End:" | tr -s " " | cut -d " " -f 2,3 2>&1)

			if [ -n "${job_starttime}" ]
			then
				text_output_history="${text_output_history}\t\t{\n\t\t\t\"job_id\": \"${job_id}\",\n\t\t\t\"job_nodes\": \"${job_nodes}\",\n\t\t\t\"job_cores\": \"${job_cores}\",\n\t\t\t\"job_walltime\": \"${job_walltime}\",\n\t\t\t\"job_queuetime\": \"${job_queuetime}\",\n\t\t\t\"job_starttime\": \"${job_starttime}\",\n\t\t\t\"job_endtime\": \"${job_endtime}\"\n\t\t},\n"
			fi
		done
	fi

	#remove last ,
	if [ -n "$text_output" ]
	then
		text_output="$(echo "$text_output" | rev | cut -c 4- | rev)"
	fi
	text_output="${text_output}\n"

	#remove last ,
	if [ -n "$text_output_history" ]
	then
		text_output_history="$(echo "$text_output_history" | rev | cut -c 4- | rev)"
	fi
	text_output_history="${text_output_history}\n"


	echo -e "{\n\t\"statuses\": [\n${text_output}\t],\n\t\"history\": [\n${text_output_history}\t],\n\t\"result\": \"OK\"\n}"
}

function status_slurm {
	#translate slurm states to pbs states
	declare -A state
	state["PENDING"]="QUEUED"
	state["RUNNING"]="RUNNING"
	state["SUSPENDED"]="RUNNING"
	state["CANCELLED"]="RUNNING"
	state["COMPLETING"]="RUNNING"
	state["COMPLETED"]="RUNNING"
	state["CONFIGURING"]="RUNNING"
	state["FAILED"]="ERROR"
	state["TIMEOUT"]="ERROR"
	state["PREEMPTED"]="ERROR"
	state["NODE_FAIL"]="ERROR"
	state["SPECIAL_EXIT"]="ERROR"

	declare -a job_list=($@)
	comma_job_list=$(sed -e "s/ /,/g" <<< ${job_list[@]})

	text_output=""
	text_output_history=""

    job_states=$($SQUEUE -h -u $USER -o "%A|%T" -j $comma_job_list 2>&1)
	for job_id in "${job_list[@]}"
	do
        job_state=$(echo "$job_states" | grep $job_id | cut -f 2 -d "|" 2>&1)
		if [ $? -ne 0 -o "x${job_state}" = "x" ]
		then
			#report_error "squeue error! $job_state"
			#exit 13
			continue
		fi
		text_output="${text_output}\t\t{\n\t\t\t\"job_id\": \"${job_id}\",\n\t\t\t\"job_state\": \"${state[${job_state}]}\"\n\t\t},\n"
	done

	if [ "plgmonitoring" != $USER ]
	then
	    since=$(date --date "week ago" +%F)
	    saout=$($SACCT -Xp -o JobID,NNodes,NCPUS,Elapsed,Submit,Start,End -S ${since} -n -s BF,CA,F,NF,PR,TO,CD -j $comma_job_list)
		for job_id in "${job_list[@]}"
		do
			job_nodes=$(echo "$saout" | grep $job_id | cut -f 2 -d "|" 2>&1)
			job_cores=$(echo "$saout" | grep $job_id | cut -f 3 -d "|" 2>&1)
			job_walltime=$(echo "$saout" | grep $job_id | cut -f 4 -d "|" 2>&1)
			job_queuetime=$(echo "$saout" | grep $job_id | cut -f 5 -d "|" 2>&1)
			job_starttime=$(echo "$saout" | grep $job_id | cut -f 6 -d "|" 2>&1)
			job_endtime=$(echo "$saout" | grep $job_id | cut -f 7 -d "|" 2>&1)

			if [ -n "${job_starttime}" ]
			then
				text_output_history="${text_output_history}\t\t{\n\t\t\t\"job_id\": \"${job_id}\",\n\t\t\t\"job_nodes\": \"${job_nodes}\",\n\t\t\t\"job_cores\": \"${job_cores}\",\n\t\t\t\"job_walltime\": \"${job_walltime}\",\n\t\t\t\"job_queuetime\": \"${job_queuetime}\",\n\t\t\t\"job_starttime\": \"${job_starttime}\",\n\t\t\t\"job_endtime\": \"${job_endtime}\"\n\t\t},\n"
			fi
		done
	fi

	#remove last ,
	if [ -n "$text_output" ]
	then
		text_output="$(echo "$text_output" | rev | cut -c 4- | rev)"
	fi
	text_output="${text_output}\n"

	#remove last ,
	if [ -n "$text_output_history" ]
	then
		text_output_history="$(echo "$text_output_history" | rev | cut -c 4- | rev)"
	fi
	text_output_history="${text_output_history}\n"


	echo -e "{\n\t\"statuses\": [\n${text_output}\t],\n\t\"history\": [\n${text_output_history}\t],\n\t\"result\": \"OK\"\n}"
}


if [ "$1" = "-h" -o "$#" -eq "0" ]
then
	usage
	exit 1
fi

detect_rm

if [ "$RM" == "torque" ]
then
	status_torque $@
elif [ "$RM" == "slurm" ]
then
	status_slurm $@
else
	report_error "Unable to determine resource manager"
	exit 2
fi

